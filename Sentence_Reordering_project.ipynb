{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Sentence Reconstruction","metadata":{"id":"ElNaMbLnRdHR"}},{"cell_type":"markdown","source":"The purpose of this project is to take in input a sequence of words corresponding to a random permutation of a given english sentence, and reconstruct the original sentence.\n\nThe otuput can be either produced in a single shot, or through an iterative (autoregressive) loop generating a single token at a time.\n\n\nCONSTRAINTS:\n* No pretrained model can be used.\n* The neural network models should have less the 20M parameters.\n* No postprocessing should be done (e.g. no beamsearch)\n* You cannot use additional training data.\n\n\nBONUS PARAMETERS:\n\nA bonus of 0-2 points will be attributed to incentivate the adoption of models with a low number of parameters.","metadata":{"id":"oXr4iGUGRms8"}},{"cell_type":"markdown","source":"# Dataset\n\nThe dataset is composed by sentences taken from the generics_kb dataset of hugging face. We restricted the vocabolary to the 10K most frequent words, and only took sentences making use of this vocabulary.","metadata":{"id":"iQ8k-L-WUK7l"}},{"cell_type":"code","source":"!pip install datasets","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nJ02vehGYySk","outputId":"a165d5cd-ec0d-4efd-9902-d9db99806756","execution":{"iopub.status.busy":"2024-06-12T07:15:26.888539Z","iopub.execute_input":"2024-06-12T07:15:26.888794Z","iopub.status.idle":"2024-06-12T07:15:40.971000Z","shell.execute_reply.started":"2024-06-12T07:15:26.888772Z","shell.execute_reply":"2024-06-12T07:15:40.969868Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.19.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (14.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.1)\nRequirement already satisfied: requests>=2.32.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets) (2024.3.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.23.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install --upgrade tensorflow\n!pip install --upgrade keras","metadata":{"id":"HKntF9du2oL7","execution":{"iopub.status.busy":"2024-06-12T07:15:40.973120Z","iopub.execute_input":"2024-06-12T07:15:40.973455Z","iopub.status.idle":"2024-06-12T07:17:08.399664Z","shell.execute_reply.started":"2024-06-12T07:15:40.973418Z","shell.execute_reply":"2024-06-12T07:17:08.398557Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.15.0)\nCollecting tensorflow\n  Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=3.10.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\nCollecting ml-dtypes~=0.3.1 (from tensorflow)\n  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.32.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.9.0)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.14.1)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.59.3)\nCollecting tensorboard<2.17,>=2.16 (from tensorflow)\n  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: keras>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.3)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.35.0)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.26.4)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (13.7.0)\nRequirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\nRequirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.5.2)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.3)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (2.17.2)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\nDownloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n\u001b[?25hDownloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: ml-dtypes, tensorboard, tensorflow\n  Attempting uninstall: ml-dtypes\n    Found existing installation: ml-dtypes 0.2.0\n    Uninstalling ml-dtypes-0.2.0:\n      Successfully uninstalled ml-dtypes-0.2.0\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.15.1\n    Uninstalling tensorboard-2.15.1:\n      Successfully uninstalled tensorboard-2.15.1\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.15.0\n    Uninstalling tensorflow-2.15.0:\n      Successfully uninstalled tensorflow-2.15.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\ntensorflow-decision-forests 1.8.1 requires tensorflow~=2.15.0, but you have tensorflow 2.16.1 which is incompatible.\ntensorflow-text 2.15.0 requires tensorflow<2.16,>=2.15.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.16.1 which is incompatible.\ntf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.16.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed ml-dtypes-0.3.2 tensorboard-2.16.2 tensorflow-2.16.1\nRequirement already satisfied: keras in /opt/conda/lib/python3.10/site-packages (3.3.3)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from keras) (1.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from keras) (1.26.4)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras) (13.7.0)\nRequirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras) (0.0.8)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras) (3.10.0)\nRequirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras) (0.11.0)\nRequirement already satisfied: ml-dtypes in /opt/conda/lib/python3.10/site-packages (from keras) (0.3.2)\nRequirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from optree->keras) (4.9.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras) (2.17.2)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Download the dataset","metadata":{"id":"807Wk-ir_bDU"}},{"cell_type":"code","source":"from datasets import load_dataset\nfrom keras.layers import TextVectorization\nimport tensorflow as tf\nimport numpy as np\nnp.random.seed(42)\nds = load_dataset('generics_kb',trust_remote_code=True)['train']","metadata":{"id":"_WjtqA8TrHcS","execution":{"iopub.status.busy":"2024-06-12T07:17:08.401328Z","iopub.execute_input":"2024-06-12T07:17:08.401649Z","iopub.status.idle":"2024-06-12T07:18:42.294488Z","shell.execute_reply.started":"2024-06-12T07:17:08.401618Z","shell.execute_reply":"2024-06-12T07:18:42.293627Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/8.64k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32f594dad7bb462483aa9caa0096d7c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/11.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2bbb85d1a022486d816a2f45dfa10600"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/27.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2342d6b9aba94dbc8303bc3d63c12d2f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1020868 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fcff0647b7384af0bd83efde31bc248f"}},"metadata":{}}]},{"cell_type":"markdown","source":"Filter row with length greater than 8.\n","metadata":{"id":"lAVLfsdc_ej5"}},{"cell_type":"code","source":"ds = ds.filter(lambda row: len(row[\"generic_sentence\"].split(\" \")) > 8 )\ncorpus = [ '<start> ' + row['generic_sentence'].replace(\",\",\" <comma>\") + ' <end>' for row in ds ]\ncorpus = np.array(corpus)\n","metadata":{"id":"iznq8xGNt2Zr","execution":{"iopub.status.busy":"2024-06-12T07:18:42.296491Z","iopub.execute_input":"2024-06-12T07:18:42.296772Z","iopub.status.idle":"2024-06-12T07:19:56.745533Z","shell.execute_reply.started":"2024-06-12T07:18:42.296747Z","shell.execute_reply":"2024-06-12T07:19:56.744660Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/1020868 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36c5d4de6a8f4f97836e832102855de6"}},"metadata":{}}]},{"cell_type":"markdown","source":"Create a tokenizer and Detokenizer","metadata":{"id":"FyYpXLCF_ldR"}},{"cell_type":"code","source":"tokenizer=TextVectorization( max_tokens=10000, standardize=\"lower_and_strip_punctuation\", encoding=\"utf-8\",) #con il max prende le piu frequenti. ordina i token del vocab dal piu frequente al meno frequente\ntokenizer.adapt(corpus)\n\nclass TextDetokenizer:\n    def __init__(self, vectorize_layer):\n        self.vectorize_layer = vectorize_layer\n        vocab = self.vectorize_layer.get_vocabulary()\n        self.index_to_word = {index: word for index, word in enumerate(vocab)}\n\n    def __detokenize_tokens(self, tokens):\n        def check_token(t):\n          if t == 3:\n            s=\"<start>\"\n          elif t == 2:\n            s=\"<end>\"\n          elif t == 7:\n            s=\"<comma>\"\n          else:\n            s=self.index_to_word.get(t, '[UNK]')\n          return s\n\n        return ' '.join([ check_token(token) for token in tokens if token != 0])\n\n    def __call__(self, batch_tokens):\n       return [self.__detokenize_tokens(tokens) for tokens in batch_tokens]\n\n\ndetokenizer = TextDetokenizer( tokenizer )\nsentences = tokenizer( corpus ).numpy()","metadata":{"id":"T-bE2JpVbU9E","execution":{"iopub.status.busy":"2024-06-12T07:19:56.746746Z","iopub.execute_input":"2024-06-12T07:19:56.747164Z","iopub.status.idle":"2024-06-12T07:20:04.419701Z","shell.execute_reply.started":"2024-06-12T07:19:56.747128Z","shell.execute_reply":"2024-06-12T07:20:04.418913Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"Remove from corpus the sentences where any unknow word appears","metadata":{"id":"lZ64sns1_pSK"}},{"cell_type":"code","source":"mask = np.sum( (sentences==1), axis=1) >= 1\noriginal_data = np.delete( sentences, mask , axis=0)","metadata":{"id":"2LPQtryQz5wh","execution":{"iopub.status.busy":"2024-06-12T07:20:04.420857Z","iopub.execute_input":"2024-06-12T07:20:04.421155Z","iopub.status.idle":"2024-06-12T07:20:04.477383Z","shell.execute_reply.started":"2024-06-12T07:20:04.421130Z","shell.execute_reply":"2024-06-12T07:20:04.476603Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"original_data.shape","metadata":{"id":"qYfOscVk7U0r","execution":{"iopub.status.busy":"2024-06-12T07:20:04.478513Z","iopub.execute_input":"2024-06-12T07:20:04.478811Z","iopub.status.idle":"2024-06-12T07:20:04.485797Z","shell.execute_reply.started":"2024-06-12T07:20:04.478787Z","shell.execute_reply":"2024-06-12T07:20:04.484778Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(241236, 28)"},"metadata":{}}]},{"cell_type":"markdown","source":"Shuffle the sentences","metadata":{"id":"5puiiQ2D_uxa"}},{"cell_type":"code","source":"from tensorflow.keras.utils import PyDataset\n\nclass DataGenerator(PyDataset):\n    def __init__(self, data, batch_size=32, shuffle=True, seed=42):\n        self.data = data\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.seed = seed\n        self.on_epoch_end()\n\n\n    def __len__(self):\n        return int(np.floor(len(self.data) / self.batch_size))\n\n    def __getitem__(self, index):\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        data_batch = np.array([self.data[k] for k in indexes])\n        #copy of ordered sequences\n        result = np.copy(data_batch)\n        #shuffle only the relevant positions for each batch\n        for i in range(data_batch.shape[0]):\n          np.random.shuffle(data_batch[i,1:data_batch[i].argmin() - 1])\n\n        return (data_batch , np.array([[result[i][j] for j in range(1,len(result[i]))] for i in range(len(result))] )), np.array([[result[i][j] for j in range(len(result[i])-1)] for i in range(len(result))])\n\n    def on_epoch_end(self):\n        self.indexes = np.arange(len(self.data))\n        if self.shuffle:\n            if self.seed is not None:\n                np.random.seed(self.seed)\n            np.random.shuffle(self.indexes)","metadata":{"id":"1ZXLkWB6od0R","execution":{"iopub.status.busy":"2024-06-12T07:20:04.487127Z","iopub.execute_input":"2024-06-12T07:20:04.487544Z","iopub.status.idle":"2024-06-12T07:20:04.534883Z","shell.execute_reply.started":"2024-06-12T07:20:04.487512Z","shell.execute_reply":"2024-06-12T07:20:04.534015Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Make a random permutation of training and test set\nnp.random.seed(42)\n# Shuffle the all data\nshuffled_indices = np.random.permutation(len(original_data))\nshuffled_data = original_data[shuffled_indices]","metadata":{"id":"fNo_Jy3N8zHS","execution":{"iopub.status.busy":"2024-06-12T07:20:04.536086Z","iopub.execute_input":"2024-06-12T07:20:04.536423Z","iopub.status.idle":"2024-06-12T07:20:04.578236Z","shell.execute_reply.started":"2024-06-12T07:20:04.536391Z","shell.execute_reply":"2024-06-12T07:20:04.577395Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#split the dataset\ntrain_generator = DataGenerator(shuffled_data[:220000])\ntest_generator = DataGenerator(shuffled_data[220000:])","metadata":{"id":"uNlq1Khx1oH2","execution":{"iopub.status.busy":"2024-06-12T07:20:04.582252Z","iopub.execute_input":"2024-06-12T07:20:04.582891Z","iopub.status.idle":"2024-06-12T07:20:04.593416Z","shell.execute_reply.started":"2024-06-12T07:20:04.582863Z","shell.execute_reply":"2024-06-12T07:20:04.592445Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"(x, y), z = test_generator.__getitem__(1)\nx = detokenizer(x)\ny = detokenizer(y)\nz = detokenizer(z)\n\nfor i in range(7):\n  print(\"shuffled: \", x[i])\n  print(\"original shifted: \", y[i])\n  print(\"original: \", z[i])\n  print(\"\\n\")\n","metadata":{"id":"qR5xwMOn4E88","execution":{"iopub.status.busy":"2024-06-12T07:20:04.594658Z","iopub.execute_input":"2024-06-12T07:20:04.595064Z","iopub.status.idle":"2024-06-12T07:20:04.610206Z","shell.execute_reply.started":"2024-06-12T07:20:04.595033Z","shell.execute_reply":"2024-06-12T07:20:04.609258Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"shuffled:  <start> large their areas for cattle ranchers rainforest clear pastures become to of <end>\noriginal shifted:  ranchers clear large areas of rainforest to become pastures for their cattle <end>\noriginal:  <start> ranchers clear large areas of rainforest to become pastures for their cattle <end>\n\n\nshuffled:  <start> stripes thorax some and the earwigs on abdomen have <end>\noriginal shifted:  some earwigs have stripes on the thorax and abdomen <end>\noriginal:  <start> some earwigs have stripes on the thorax and abdomen <end>\n\n\nshuffled:  <start> into in magnetic such a liquid molecules can manipulation computing turn devices <end>\noriginal shifted:  magnetic manipulation can turn molecules in a liquid into computing such devices <end>\noriginal:  <start> magnetic manipulation can turn molecules in a liquid into computing such devices <end>\n\n\nshuffled:  <start> reduced wetlands and recreation for water places healthy cleaner flooding <comma> means more <end>\noriginal shifted:  healthy wetlands means cleaner water <comma> reduced flooding and more places for recreation <end>\noriginal:  <start> healthy wetlands means cleaner water <comma> reduced flooding and more places for recreation <end>\n\n\nshuffled:  <start> company percent share one controls a sales in market is share the particular in market <end>\noriginal shifted:  market share is the percent share in sales one company controls in a particular market <end>\noriginal:  <start> market share is the percent share in sales one company controls in a particular market <end>\n\n\nshuffled:  <start> of on animal only a the small flies time amount spend face <end>\noriginal shifted:  face flies spend only a small amount of time on the animal <end>\noriginal:  <start> face flies spend only a small amount of time on the animal <end>\n\n\nshuffled:  <start> extremely management in of foods are prevention and cancer important organic <end>\noriginal shifted:  organic foods are extremely important in prevention and management of cancer <end>\noriginal:  <start> organic foods are extremely important in prevention and management of cancer <end>\n\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Metrics","metadata":{"id":"Fo8MazCGBTv3"}},{"cell_type":"markdown","source":"Let s be the source string and p your prediction. The quality of the results will be measured according to the following metric:\n\n1.  look for the longest substring w between s and p\n2.  compute |w|/max(|s|,|p|)\n\nIf the match is exact, the score is 1.\n\nWhen computing the score, you should NOT consider the start and end tokens.\n\n","metadata":{"id":"G0NOkuO0CfPo"}},{"cell_type":"markdown","source":"The longest common substring can be computed with the SequenceMatcher function of difflib, that allows a simple definition of our metric.","metadata":{"id":"a-aUrdlXDdVf"}},{"cell_type":"code","source":"from difflib import SequenceMatcher\n\ndef score(s,p):\n  match = SequenceMatcher(None, s, p).find_longest_match()\n  #print(match.size)\n  return (match.size/max(len(p),len(s)))","metadata":{"id":"ulpTRdrF_huh","execution":{"iopub.status.busy":"2024-06-12T07:20:04.611154Z","iopub.execute_input":"2024-06-12T07:20:04.611456Z","iopub.status.idle":"2024-06-12T07:20:04.616979Z","shell.execute_reply.started":"2024-06-12T07:20:04.611432Z","shell.execute_reply":"2024-06-12T07:20:04.615820Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"Let's do an example.","metadata":{"id":"RB2YfjXNExM-"}},{"cell_type":"code","source":"original = \"at first henry wanted to be friends with the king of france\"\ngenerated = \"henry wanted to be friends with king of france at the first\"\n\nprint(\"your score is \",score(original,generated))","metadata":{"id":"h17C8bVjEwur","execution":{"iopub.status.busy":"2024-06-12T07:20:04.618321Z","iopub.execute_input":"2024-06-12T07:20:04.618721Z","iopub.status.idle":"2024-06-12T07:20:04.628354Z","shell.execute_reply.started":"2024-06-12T07:20:04.618651Z","shell.execute_reply":"2024-06-12T07:20:04.627458Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"your score is  0.5423728813559322\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The score must be computed as an average of at least 3K random examples taken form the test set.","metadata":{"id":"BET8GqBvFugR"}},{"cell_type":"markdown","source":"# What to deliver","metadata":{"id":"4fwo7xj4GBW1"}},{"cell_type":"markdown","source":"You are supposed to deliver a single notebook, suitably commented.\nThe notebook should describe a single model, although you may briefly discuss additional attempts you did.\n\nThe notebook should contain a full trace of the training.\nWeights should be made available on request.\n\nYou must also give a clear assesment of the performance of the model, computed with the metric that has been given to you.\n\n# Good work!","metadata":{"id":"i6uITuxOGHfJ"}},{"cell_type":"markdown","source":"<p>For this task it has been decided to implement a Transformer, for this reason we will define a Decoder and Encoder Block working with multiple attention heads in an attention based Transformer.<p>","metadata":{}},{"cell_type":"markdown","source":"# Model Definition","metadata":{"id":"xTVgCp8976tK"}},{"cell_type":"markdown","source":"Useful parameters:\n1. LEN_VOC: Length of the vocabulary considered\n2. LEN_SENT: Maximum length of the input sentence\n3. LEN_TARGET_SENT: Maximum length of the input sentence\n4. LEN_EMBED: Dimension of the embedding space\n5. HEADS_1: Number of heads for the first Attention layer\n6. HEADS_2: Number of heads for the second Attention layer\n7. LEN_FF: Dimension of the Feed-Forward layer\n8. DROPOUT: Dropout rate","metadata":{}},{"cell_type":"code","source":"LEN_VOC = 10000\nLEN_SENT = 28\nLEN_TARGET_SENT= 27\nLEN_EMBED = 64\nHEADS_1 = 6\nHEADS_2 = 6\nLEN_FF = 256\nDROPOUT=0.01","metadata":{"id":"1ft2CGyr5SsH","execution":{"iopub.status.busy":"2024-06-12T07:20:04.629476Z","iopub.execute_input":"2024-06-12T07:20:04.630090Z","iopub.status.idle":"2024-06-12T07:20:04.643042Z","shell.execute_reply.started":"2024-06-12T07:20:04.630057Z","shell.execute_reply":"2024-06-12T07:20:04.642163Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Encoder Layer\n","metadata":{"id":"If9LX6q-8AQt"}},{"cell_type":"markdown","source":"The Encoder block is constituted by the Embedding layer (Token and Positional encoding the token itslef and the position it occupies in the sentence) and several EncoderLayers (stacking more layers is considered to offer a more accurate solution).<br>\nThe EncoderLayer is composed by two MultiHeadAttention layers and a Feed-Forward one, after every layer we apply a normalization to avoid gradient explosion.","metadata":{}},{"cell_type":"code","source":"class EncoderLayer(tf.keras.layers.Layer):\n     def __init__(self, num_heads_1, num_heads_2, ff_size, embed_size):\n        super().__init__() \n        \n        #First self attention layer + normalization layer\n        self.multihead1 = tf.keras.layers.MultiHeadAttention(num_heads=num_heads_1, key_dim=LEN_EMBED)\n        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n\n        #Second self attention layer + normalization layer\n        self.multihead2= tf.keras.layers.MultiHeadAttention(num_heads=num_heads_2, key_dim=LEN_EMBED)\n        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n\n        #Feed-forward dense layer + normalization layer\n        self.ffn = tf.keras.Sequential([tf.keras.layers.Dense(ff_size, activation=\"leaky_relu\"), tf.keras.layers.Dense(LEN_EMBED),])\n        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n        \n        #Dropout layer\n        self.dropout = tf.keras.layers.Dropout(rate=DROPOUT)\n\n\n     def call(self, inputs):\n        \n        #Self Attention Section 1\n        attn_output_1 = self.multihead1(inputs, inputs)\n        out_1 = self.layernorm1(inputs + attn_output_1)\n        \n        \n        #Self Attention Section 2\n        attn_output_2 = self.multihead2(out_1, out_1)\n        out_2 = self.layernorm2(out_1 + attn_output_2)\n\n        #Feed Forward Section\n        ffn_output = self.ffn(out_2)\n        ffn_output = self.dropout(ffn_output)\n        out_3 = self.layernorm3(out_2 + ffn_output)\n\n        return out_3\n\nclass Encoder(tf.keras.layers.Layer):\n  def __init__(self, num_heads_1, num_heads_2, ff_size, embed_size):\n    super().__init__()\n    self.token_embedding = tf.keras.layers.Embedding(input_dim=LEN_VOC, output_dim=LEN_EMBED, mask_zero=True)\n    self.pos_embedding = tf.keras.layers.Embedding(input_dim=LEN_SENT, output_dim=LEN_EMBED)\n    self.encoder_1 = EncoderLayer(num_heads_1, num_heads_2, ff_size, embed_size)\n    self.encoder_2 = EncoderLayer(num_heads_1, num_heads_2, ff_size, embed_size)\n    self.encoder_3 = EncoderLayer(num_heads_1, num_heads_2, ff_size, embed_size)\n    self.encoder_4 = EncoderLayer(num_heads_1, num_heads_2, ff_size, embed_size)\n    self.encoder_5 = EncoderLayer(num_heads_1, num_heads_2, ff_size, embed_size)\n    \n\n\n  def call(self, inputs):\n\n        x=inputs\n        #Token and Position Encoding Section\n        maxlen = tf.shape(x)[-1]\n        positions = tf.keras.ops.arange(start=0, stop=maxlen, step=1)\n        positions = self.pos_embedding(positions)\n        x = self.token_embedding(x) #shape (batch_size, len_sen, len_emb)\n        \n\n        out_1 = x + positions #positional encoding in the beginning not taken into account\n        \n        out_2 = self.encoder_1(out_1)\n        out_3 = self.encoder_2(out_2)\n        out_4 = self.encoder_3(out_3)\n        out_5 = self.encoder_4(out_4)\n        out_6 = self.encoder_5(out_5)\n        return out_6\n\n","metadata":{"id":"OxawHPkOkmEx","execution":{"iopub.status.busy":"2024-06-12T07:20:04.644406Z","iopub.execute_input":"2024-06-12T07:20:04.644739Z","iopub.status.idle":"2024-06-12T07:20:04.661183Z","shell.execute_reply.started":"2024-06-12T07:20:04.644701Z","shell.execute_reply":"2024-06-12T07:20:04.660274Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Decoder Layer\n","metadata":{"id":"R3whFryPrBfP"}},{"cell_type":"markdown","source":"The Decoder block is similarly structured, in fact we have the embedding followed by a series of DecoderLayers as in the Encoder described above. In addition to the two SelfAttention layers we have also a CausalAttention layer here, considerin in this way only the tokens already predicted/observed. In this block, as in the previous one, defining the layers we considered normalizing to avoid gradient explosion.","metadata":{}},{"cell_type":"code","source":"class DecoderLayer(tf.keras.layers.Layer):\n    def __init__(self, num_heads_1, num_heads_2, ff_size, embed_size):\n        super().__init__() \n\n        self.multihead_mask = tf.keras.layers.MultiHeadAttention(num_heads=num_heads_1, key_dim=LEN_EMBED)\n        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n\n        self.multihead1 = tf.keras.layers.MultiHeadAttention(num_heads=num_heads_1, key_dim=LEN_EMBED)\n        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n\n        self.multihead2 = tf.keras.layers.MultiHeadAttention(num_heads=num_heads_2, key_dim=LEN_EMBED)\n        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n\n        self.ffn = tf.keras.Sequential([tf.keras.layers.Dense(ff_size, activation=\"leaky_relu\"), tf.keras.layers.Dense(LEN_EMBED),])\n        self.layernorm4 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n\n        self.dropout = tf.keras.layers.Dropout(rate=DROPOUT)\n\n    \n    \n    def call(self, encoder_out, decoder_inp_embed):\n        \n \n        #Causal Attention Section\n        causal_output = self.multihead_mask(decoder_inp_embed, decoder_inp_embed, use_causal_mask=True)\n        out_1 = self.layernorm1(decoder_inp_embed + causal_output)\n\n        #Self Attention Section 1\n        attn_output_1 = self.multihead1(out_1, encoder_out)\n        out_2= self.layernorm2(out_1 + attn_output_1)\n\n        #Self Attention Section 2\n        attn_output_2 = self.multihead2(out_2, encoder_out)\n        out_3 = self.layernorm3(out_2 + attn_output_2)\n\n        #Feed Forward Section\n        ffn_output = self.ffn(out_3)\n        ffn_output = self.dropout(ffn_output)\n        out_4 = self.layernorm4(out_3 + ffn_output)\n\n        return out_4\n\n\nclass Decoder(tf.keras.layers.Layer):\n  def __init__(self, num_heads_1, num_heads_2, ff_size,embed_size):\n    super().__init__()\n    self.token_embedding = tf.keras.layers.Embedding(input_dim=LEN_VOC, output_dim=LEN_EMBED, mask_zero=True)\n    self.pos_embedding = tf.keras.layers.Embedding(input_dim=LEN_TARGET_SENT, output_dim=LEN_EMBED)\n    self.decoder_1 = DecoderLayer(num_heads_1, num_heads_2, ff_size, embed_size)\n    self.decoder_2 = DecoderLayer(num_heads_1, num_heads_2, ff_size, embed_size)\n    self.decoder_3 = DecoderLayer(num_heads_1, num_heads_2, ff_size, embed_size)\n    self.decoder_4 = DecoderLayer(num_heads_1, num_heads_2, ff_size, embed_size)\n    self.decoder_5 = DecoderLayer(num_heads_1, num_heads_2, ff_size, embed_size)\n    self.outlayer = tf.keras.layers.Dense(LEN_VOC, activation='softmax')\n\n\n  def call(self, encoder_out, decoder_inp):\n            \n        x=decoder_inp\n        #Token and Position Encoding Section\n        maxlen = tf.shape(x)[-1]\n        positions = tf.keras.ops.arange(start=0, stop=maxlen, step=1)\n        positions = self.pos_embedding(positions)\n        x = self.token_embedding(x)\n        out_1 = x + positions\n        \n        out_2 = self.decoder_1(encoder_out, out_1)\n        out_3 = self.decoder_2(encoder_out, out_2)\n        out_4 = self.decoder_3(encoder_out, out_3)\n        out_5 = self.decoder_4(encoder_out, out_4)\n        out_6 = self.decoder_5(encoder_out, out_5)\n        \n\n\n        return self.outlayer(out_6)","metadata":{"id":"5hvmCnfDoRFX","execution":{"iopub.status.busy":"2024-06-12T07:20:04.662501Z","iopub.execute_input":"2024-06-12T07:20:04.662761Z","iopub.status.idle":"2024-06-12T07:20:04.681635Z","shell.execute_reply.started":"2024-06-12T07:20:04.662741Z","shell.execute_reply":"2024-06-12T07:20:04.680877Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## Transformer","metadata":{"id":"OXDmjxuMuf1f"}},{"cell_type":"markdown","source":"We merge together the Encoder and the Decoder block. We also override the predict method of the class Model to predict the ordered sentences.","metadata":{}},{"cell_type":"code","source":"class Transformer(tf.keras.Model):\n    def __init__(self, num_heads_1, num_heads_2, ff_size, embed_size):\n            super().__init__()\n            self.encoder = Encoder(num_heads_1, num_heads_2, ff_size, embed_size)\n    \n            self.decoder = Decoder(num_heads_1, num_heads_2, ff_size, embed_size)\n\n            \n            \n\n    \n    def generate_initial_decoder_input(self, batch_size):\n        start_token = tf.constant([3], dtype=tf.int32)  # Assuming 3 is the start token\n        return tf.tile(tf.expand_dims(start_token, 0), [batch_size, 1])\n    \n    def call(self, encoder_inp, training):\n       \n        encoder_input, decoder_inp = encoder_inp\n        encoder_out = self.encoder(encoder_input)\n        \n        decoder_out = self.decoder(encoder_out, decoder_inp)\n        \n        return decoder_out\n    \n        \n    def predict(self, x, *args, **kwargs):\n        encoder_input, decoder_inputs = x\n\n        max_length = 28\n\n        batch_size = encoder_input.shape[0]\n        output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n\n        start = np.array(tokenizer.word_index[''], ndmin=1)\n        output_array = output_array.write(0, tf.tile(start, [batch_size]))\n\n        for i in tf.range(max_length-1):\n            output = tf.transpose(output_array.stack())\n            predictions = self([encoder_input, output], training=False)\n\n            # Select the last token from the seq_len dimension.\n            predictions = predictions[:, -1:, :]  # Shape (batch_size, 1, vocab_size).\n\n            predicted_id = tf.argmax(predictions, axis=-1)\n\n            # Concatenate the predicted_id to the output which is given to the\n            # decoder as its input.\n            output_array = output_array.write(i+1, predicted_id[:, 0])\n        \n            end_mask = tf.reduce_any(tf.equal(predicted_id, tokenizer.word_index['']), axis=-1)\n            if tf.reduce_all(end_mask):\n                  break\n\n        output = tf.transpose(output_array.stack())\n        self([encoder_input, output[:,:-1]], training=False)\n      \n        return output      ","metadata":{"id":"fY-ILdAstWdU","execution":{"iopub.status.busy":"2024-06-12T07:20:04.682721Z","iopub.execute_input":"2024-06-12T07:20:04.683040Z","iopub.status.idle":"2024-06-12T07:20:04.697322Z","shell.execute_reply.started":"2024-06-12T07:20:04.683017Z","shell.execute_reply":"2024-06-12T07:20:04.696528Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"We instantiate the model (the number of trainable parameters is really low in order to stay below the maximum parameters limit set at 20M)","metadata":{}},{"cell_type":"code","source":"training=False\ninputs = tf.keras.Input(shape=(LEN_SENT,))\ntarget = tf.keras.Input(shape=(LEN_TARGET_SENT,))\noutputs = Transformer(HEADS_1,HEADS_2, LEN_FF, LEN_EMBED)(encoder_inp=[inputs, target], training=training)\nmodel = tf.keras.Model(inputs=[inputs, target], outputs=outputs)\nmodel.summary()","metadata":{"id":"pbOkPl86wEz_","execution":{"iopub.status.busy":"2024-06-12T07:42:13.278919Z","iopub.execute_input":"2024-06-12T07:42:13.279274Z","iopub.status.idle":"2024-06-12T07:42:22.346943Z","shell.execute_reply.started":"2024-06-12T07:42:13.279248Z","shell.execute_reply":"2024-06-12T07:42:22.346061Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_23\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_23\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_12      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ input_layer_13      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ transformer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m10000\u001b[0m) │  \u001b[38;5;34m4,756,880\u001b[0m │ input_layer_12[\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mTransformer\u001b[0m)       │                   │            │ input_layer_13[\u001b[38;5;34m0\u001b[0m… │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_12      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ input_layer_13      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ transformer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10000</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,756,880</span> │ input_layer_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Transformer</span>)       │                   │            │ input_layer_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,756,880\u001b[0m (18.15 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,756,880</span> (18.15 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,756,880\u001b[0m (18.15 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,756,880</span> (18.15 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"markdown","source":"Now, after creating the generators for the training, the validation and the testing (all mantaining the proportions between training and testing) we procede with the training of the model.","metadata":{}},{"cell_type":"code","source":"train_generator = DataGenerator(original_data[:210000], batch_size=32)\nvalidation_generator = DataGenerator(original_data[210000:220000], batch_size=32)\ntest_generator = DataGenerator(original_data[220000:], batch_size=32)\n\nopt = tf.keras.optimizers.AdamW(0.00005, gradient_accumulation_steps=4)\nmodel.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nhistory = model.fit(train_generator, batch_size=32, epochs=10, validation_data=validation_generator)\n\nmodel.summary()","metadata":{"id":"-EUTl_-KiFNK","execution":{"iopub.status.busy":"2024-06-12T07:42:27.908391Z","iopub.execute_input":"2024-06-12T07:42:27.908758Z","iopub.status.idle":"2024-06-12T08:23:41.277721Z","shell.execute_reply.started":"2024-06-12T07:42:27.908728Z","shell.execute_reply":"2024-06-12T08:23:41.276816Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1718178213.958220     125 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m6562/6562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4718 - loss: 6.3240","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1718178494.752006     126 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m6562/6562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 37ms/step - accuracy: 0.4718 - loss: 6.3237 - val_accuracy: 0.6671 - val_loss: 2.7680\nEpoch 2/10\n\u001b[1m6562/6562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 36ms/step - accuracy: 0.6872 - loss: 2.4084 - val_accuracy: 0.7609 - val_loss: 1.7253\nEpoch 3/10\n\u001b[1m6562/6562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 36ms/step - accuracy: 0.7876 - loss: 1.5353 - val_accuracy: 0.8444 - val_loss: 1.2168\nEpoch 4/10\n\u001b[1m6562/6562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 36ms/step - accuracy: 0.8699 - loss: 1.0521 - val_accuracy: 0.8996 - val_loss: 0.8641\nEpoch 5/10\n\u001b[1m6562/6562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 36ms/step - accuracy: 0.9210 - loss: 0.7203 - val_accuracy: 0.9359 - val_loss: 0.6172\nEpoch 6/10\n\u001b[1m6562/6562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 36ms/step - accuracy: 0.9524 - loss: 0.4955 - val_accuracy: 0.9590 - val_loss: 0.4497\nEpoch 7/10\n\u001b[1m6562/6562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 36ms/step - accuracy: 0.9717 - loss: 0.3472 - val_accuracy: 0.9733 - val_loss: 0.3293\nEpoch 8/10\n\u001b[1m6562/6562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 36ms/step - accuracy: 0.9837 - loss: 0.2410 - val_accuracy: 0.9829 - val_loss: 0.2404\nEpoch 9/10\n\u001b[1m6562/6562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 36ms/step - accuracy: 0.9913 - loss: 0.1662 - val_accuracy: 0.9878 - val_loss: 0.1776\nEpoch 10/10\n\u001b[1m6562/6562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 36ms/step - accuracy: 0.9956 - loss: 0.1142 - val_accuracy: 0.9920 - val_loss: 0.1313\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_23\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_23\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_12      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ input_layer_13      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ transformer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m10000\u001b[0m) │  \u001b[38;5;34m4,756,880\u001b[0m │ input_layer_12[\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mTransformer\u001b[0m)       │                   │            │ input_layer_13[\u001b[38;5;34m0\u001b[0m… │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_12      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ input_layer_13      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ transformer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10000</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,756,880</span> │ input_layer_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Transformer</span>)       │                   │            │ input_layer_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,027,522\u001b[0m (72.58 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,027,522</span> (72.58 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,756,880\u001b[0m (18.15 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,756,880</span> (18.15 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m14,270,642\u001b[0m (54.44 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,270,642</span> (54.44 MB)\n</pre>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"As we can see from the summary the total number of parameters is slightly less than the 20M parameters constraint.","metadata":{}},{"cell_type":"markdown","source":"## Testing","metadata":{"id":"TizAn4lonaun"}},{"cell_type":"code","source":"#function to determine the average score\ndef calc_score(num_batches, generator, myModel, detokenizier, score_function):\n    list_scores = []\n    for k in range(num_batches):\n      x, y = generator.__getitem__(k)\n      predictions = myModel.predict(x, batch_size=32, verbose=False)\n      best = [[np.argmax(predictions[t][:][r]) for r in range(len(predictions[t]))] for t in range(len(predictions))]\n      for i in range(len(x)):\n        list_scores.append(score(detokenizer(y)[i], detokenizer(best)[i]))\n    \n    return np.average(list_scores), np.std(list_scores), list_scores","metadata":{"id":"c7O2Vw9gv_YT","execution":{"iopub.status.busy":"2024-06-12T08:23:45.778305Z","iopub.execute_input":"2024-06-12T08:23:45.778912Z","iopub.status.idle":"2024-06-12T08:23:45.786178Z","shell.execute_reply.started":"2024-06-12T08:23:45.778881Z","shell.execute_reply":"2024-06-12T08:23:45.785274Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"#Testing the model\nbatches = round((len(original_data)-220000)/32)\nscore_value, std, scores = calc_score(batches, test_generator, model, detokenizer, score)\nprint(f\"Std is: {std}\")\nprint(f\"Average Score is: {score_value}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-12T08:23:48.646190Z","iopub.execute_input":"2024-06-12T08:23:48.646875Z","iopub.status.idle":"2024-06-12T08:25:29.009249Z","shell.execute_reply.started":"2024-06-12T08:23:48.646843Z","shell.execute_reply":"2024-06-12T08:25:29.008253Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"I0000 00:00:1718180725.228800    5877 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_149', 108 bytes spill stores, 108 bytes spill loads\n\nI0000 00:00:1718180725.877044    5874 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_147', 108 bytes spill stores, 108 bytes spill loads\n\n","output_type":"stream"},{"name":"stdout","text":"Std is: 0.10079521260642532\nAverage Score is: 0.9667937337147346\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We save the weights at the end of the run in order to have them disposable at every time","metadata":{}},{"cell_type":"code","source":"model.save_weights(\"model_weights.weights.h5\")","metadata":{"execution":{"iopub.status.busy":"2024-06-12T08:25:34.481000Z","iopub.execute_input":"2024-06-12T08:25:34.481351Z","iopub.status.idle":"2024-06-12T08:25:35.487315Z","shell.execute_reply.started":"2024-06-12T08:25:34.481319Z","shell.execute_reply":"2024-06-12T08:25:35.486330Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"## Discussion about other possible models or configurations","metadata":{}},{"cell_type":"markdown","source":"During the project it has been considered using other models like LSMT Transformers, also pretty effective in this kind of situations according to the literature, but the training time was way higher than this, so it has been chosen the Transformer architecture.<br>\nIt has also being tested to use different number of heads for different layers, but that caused a mismatch between the two attention layers that obviously affected the performance of the model.","metadata":{}}]}